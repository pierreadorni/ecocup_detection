{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T16:14:30.921537Z",
     "start_time": "2023-04-07T16:14:30.277860Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple, Generator\n",
    "import numpy as np\n",
    "from skimage import io, util, transform, color, feature\n",
    "from skimage.feature import hog\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import patches\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T16:14:30.951313Z",
     "start_time": "2023-04-07T16:14:30.922744Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate all csv files into one\n",
    "with open('data/labels.csv', 'w') as outfile:\n",
    "    for file in os.listdir('data/labels_csv'):\n",
    "        with open('data/labels_csv/' + file) as infile:\n",
    "            # add filename to each line\n",
    "            for line in infile:\n",
    "                outfile.write(file[:-4] + ',' + line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T16:21:06.449537Z",
     "start_time": "2023-04-07T16:21:06.447983Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ecocup_info(difficult: bool) -> Generator[Tuple[str, int, int, int, int], None, None]:\n",
    "    with open(\"data/labels.csv\") as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            img_name, x, y, w, h, diff = map(str.strip, line.split(','))\n",
    "            if not difficult and diff == '1':\n",
    "                # skip difficult images\n",
    "                pass\n",
    "            elif int(w) / int(h) < 1.5 or int(w) / int(h) > 2:\n",
    "                # skip images with wrong aspect ratio\n",
    "                pass\n",
    "            else:\n",
    "                yield img_name, x, y, w, h\n",
    "            line = file.readline()\n",
    "\n",
    "\n",
    "# returns a cv2 image\n",
    "def ecocup_image(image_file: str, x: int, y: int, w: int, h: int) -> np.ndarray:\n",
    "    return io.imread('data/images/pos/' + image_file + '.jpg')[int(x):int(x) + int(w), int(y):int(y) + int(h)]\n",
    "\n",
    "\n",
    "def get_pos_images(difficult=False) -> Generator[np.ndarray, None, None]:\n",
    "    # generate positive images (ecocups)\n",
    "    for info in get_ecocup_info(difficult):\n",
    "        yield info, resize_image(ecocup_image(*info), (50, 100))\n",
    "\n",
    "\n",
    "def resize_image(source: np.ndarray, size: Tuple[int, int]) -> np.ndarray:\n",
    "    return cv2.resize(source, size)\n",
    "\n",
    "\n",
    "def hog_image(image: np.ndarray) -> np.ndarray:\n",
    "    # image to greyscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return hog(image, visualize=True)\n",
    "\n",
    "def save_pos_images(save_dir: str = 'data/augmented_images', difficult: bool = False):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    for i, (info, image) in enumerate(get_pos_images(difficult)):\n",
    "        filename = f\"{i:04}.jpg\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        io.imsave(filepath, util.img_as_ubyte(image))\n",
    "\n",
    "def augment_pos_images(num_images: int = 10, save_dir: str = 'data/augmented_images', difficult: bool = False):\n",
    "    random.seed(datetime.now())\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    i = len(os.listdir(save_dir))\n",
    "    for info, image in get_pos_images(difficult):\n",
    "        for j in range(num_images):\n",
    "            # random flip\n",
    "            if random.uniform(0,1) < 0.5:\n",
    "                image = cv2.flip(image, 1)\n",
    "            if random.uniform(0,1) < 0.5:\n",
    "                augmented = image[\n",
    "                random.randint(0, int(image.shape[0]/4)):\n",
    "                random.randint(image.shape[0] - int(image.shape[0]/4), image.shape[0]),\n",
    "                random.randint(0, int(image.shape[1]/4)):\n",
    "                random.randint(image.shape[1] - int(image.shape[1]/4), image.shape[1])] # Slicing to crop the image\n",
    "            # random contrast factor between 0.75 and 1.25\n",
    "            contrast = random.uniform(0.85, 1.15)\n",
    "            # random brightness shift between -25 and 25\n",
    "            brightness = random.uniform(-20, 20)\n",
    "            # random gamma correction factor between 0.75 and 1.25\n",
    "            gamma = random.uniform(0.85, 1.15)\n",
    "            # apply color changes\n",
    "            augmented = cv2.convertScaleAbs(image, alpha=contrast, beta=brightness)\n",
    "            augmented = np.power(augmented / 255.0, gamma)\n",
    "            augmented = np.uint8(augmented * 255)\n",
    "            # save augmented image\n",
    "            filename = f\"{i:04}.jpg\"\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "            io.imsave(filepath, util.img_as_ubyte(augmented))\n",
    "            i += 1\n",
    "\n",
    "def generate_negative_images(num_images: int, save_dir: str = 'data/negative_images', source_dir: str = 'data/images/neg'):\n",
    "    random.seed(datetime.now())\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    i = len(os.listdir(save_dir))\n",
    "    for j in range(num_images):\n",
    "        # choose a random source image\n",
    "        source_file = random.choice(os.listdir(source_dir))\n",
    "        source_image = io.imread(os.path.join(source_dir, source_file))\n",
    "        # choose a random patch from the source image\n",
    "        rand = random.randint(40,60)\n",
    "        patch_size = (int(random.uniform(1.5, 2)*rand), rand)\n",
    "        patch_x = random.randint(0, max(0,source_image.shape[0] - patch_size[0]))\n",
    "        patch_y = random.randint(0, max(0,source_image.shape[1] - patch_size[1]))\n",
    "        patch = source_image[patch_x:patch_x + patch_size[0], patch_y:patch_y + patch_size[1]]\n",
    "        patch = transform.resize(patch, (200, 100))\n",
    "        # save negative image\n",
    "        filename = f\"{i:04}.jpg\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        io.imsave(filepath, util.img_as_ubyte(patch))\n",
    "        i += 1\n",
    "        \n",
    "def IoU(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # calculate intersection area\n",
    "    x_left = max(x1, x2)\n",
    "    y_top = max(y1, y2)\n",
    "    x_right = min(x1 + w1, x2 + w2)\n",
    "    y_bottom = min(y1 + h1, y2 + h2)\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        intersection_area = 0\n",
    "    else:\n",
    "        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # calculate union area\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # calculate IoU\n",
    "    if union_area == 0:\n",
    "        iou = 0\n",
    "    else:\n",
    "        iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "def train_svm_with_hog():\n",
    "    # Load positive images\n",
    "    print(\"loading pos img\")\n",
    "    pos_dir = 'data/augmented_images'\n",
    "    pos_images = []\n",
    "    for filename in os.listdir(pos_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(pos_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            pos_images.append(hog_features)\n",
    "\n",
    "    # Load negative images\n",
    "    print(\"loading neg img\")\n",
    "    neg_dir = 'data/negative_images'\n",
    "    neg_images = []\n",
    "    for filename in os.listdir(neg_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(neg_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            neg_images.append(hog_features)\n",
    "\n",
    "    # Combine positive and negative images into a single dataset\n",
    "    images = np.concatenate([pos_images, neg_images])\n",
    "    labels = np.concatenate([np.ones(len(pos_images)), np.zeros(len(neg_images))])\n",
    "\n",
    "    # split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    print(\"train model\")\n",
    "    # train the SVM\n",
    "    clf = svm.SVC(probability=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model on the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation accuracy: {acc:.2f}\")\n",
    "    \n",
    "    # save the trained model\n",
    "    model_dir = 'data/svm_model5.joblib'\n",
    "    joblib.dump(clf, model_dir)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def train_svm_poly():\n",
    "    # Load positive images\n",
    "    pos_dir = 'data/augmented_images'\n",
    "    pos_images = []\n",
    "    for filename in os.listdir(pos_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(pos_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            pos_images.append(hog_features)\n",
    "\n",
    "    # Load negative images\n",
    "    neg_dir = 'data/negative_images'\n",
    "    neg_images = []\n",
    "    for filename in os.listdir(neg_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(neg_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            neg_images.append(hog_features)\n",
    "\n",
    "    # Combine positive and negative images into a single dataset\n",
    "    images = np.concatenate([pos_images, neg_images])\n",
    "    labels = np.concatenate([np.ones(len(pos_images)), np.zeros(len(neg_images))])\n",
    "\n",
    "    # split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    print(\"train model\")\n",
    "    # train the SVM\n",
    "    clf = svm.SVC(probability=True, kernel='poly', degree=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model on the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation accuracy: {acc:.2f}\")\n",
    "    \n",
    "    # save the trained model\n",
    "    model_dir = 'data/svm_modelpoly.joblib'\n",
    "    joblib.dump(clf, model_dir)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def train_rf_with_hog():\n",
    "    # Load positive images\n",
    "    print(\"loading pos img\")\n",
    "    pos_dir = 'data/augmented_images'\n",
    "    pos_images = []\n",
    "    for filename in os.listdir(pos_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(pos_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            pos_images.append(hog_features)\n",
    "\n",
    "    # Load negative images\n",
    "    print(\"loading neg img\")\n",
    "    neg_dir = 'data/negative_images'\n",
    "    neg_images = []\n",
    "    for filename in os.listdir(neg_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(neg_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            neg_images.append(hog_features)\n",
    "\n",
    "    # Combine positive and negative images into a single dataset\n",
    "    images = np.concatenate([pos_images, neg_images])\n",
    "    labels = np.concatenate([np.ones(len(pos_images)), np.zeros(len(neg_images))])\n",
    "\n",
    "    # split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    print(\"train model\")\n",
    "    # train the Random Forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model on the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation accuracy: {acc:.2f}\")\n",
    "    \n",
    "    # save the trained model\n",
    "    model_dir = 'data/rf_model.joblib'\n",
    "    joblib.dump(clf, model_dir)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def train_adaboost_with_hog():\n",
    "    # Load positive images\n",
    "    print(\"loading pos img\")\n",
    "    pos_dir = 'data/augmented_images'\n",
    "    pos_images = []\n",
    "    for filename in os.listdir(pos_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(pos_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            pos_images.append(hog_features)\n",
    "\n",
    "    # Load negative images\n",
    "    print(\"loading neg img\")\n",
    "    neg_dir = 'data/negative_images'\n",
    "    neg_images = []\n",
    "    for filename in os.listdir(neg_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(neg_dir, filename)\n",
    "            image = io.imread(image_path)\n",
    "            # resize the image to (100, 200)\n",
    "            image = transform.resize(image, (100, 200))\n",
    "            # compute HOG features for the image\n",
    "            hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "            neg_images.append(hog_features)\n",
    "\n",
    "    # Combine positive and negative images into a single dataset\n",
    "    images = np.concatenate([pos_images, neg_images])\n",
    "    labels = np.concatenate([np.ones(len(pos_images)), np.zeros(len(neg_images))])\n",
    "\n",
    "    # split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    print(\"train model\")\n",
    "    # train the AdaBoost classifier\n",
    "    clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model on the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation accuracy: {acc:.2f}\")\n",
    "    \n",
    "    # save the trained model\n",
    "    model_dir = 'data/adaboost_model.joblib'\n",
    "    joblib.dump(clf, model_dir)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def test_model_ss(clf, test_images_dir='data/test', save_dir='data/results', result_file='data/result.csv'):\n",
    "    with open(result_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['n', 'i', 'j', 'h', 'l', 's'])  # header row\n",
    "        for n, filename in enumerate(os.listdir(test_images_dir)):\n",
    "            if not filename.endswith('.jpg'):\n",
    "                continue\n",
    "            print(n)\n",
    "            image_path = os.path.join(test_images_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            plt.imshow(image)\n",
    "            # run selective search algorithm to generate object proposals\n",
    "            ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "            ss.setBaseImage(image)\n",
    "            ss.switchToSelectiveSearchFast()\n",
    "            boxes = ss.process()\n",
    "            sorted(boxes, key=lambda x: x[2]*x[3],reverse=True)\n",
    "            \n",
    "            non_overlapping_boxes = []\n",
    "            for box in boxes:\n",
    "                x, y, h, w = box\n",
    "                if (int(w) * int(h) < 2000) or (int(w) / int(h) > 4.5) or ((int(h) / int(w) > 4.5)):\n",
    "                        continue\n",
    "                if (int(h) / int(w) < 1.5):\n",
    "                    h = int(1.5 * w)\n",
    "                if (int(h) / int(w) > 2):\n",
    "                    w = int(h / 1.5)\n",
    "                if (int(w) * int(h) < 2000):\n",
    "                        continue\n",
    "                proposal_img = image[y:y+h, x:x+w]\n",
    "                # resize the image to (100, 200)\n",
    "                proposal_img = cv2.resize(proposal_img, (100, 200))\n",
    "                plt.imshow(proposal_img)\n",
    "                # encode the image as HOG features\n",
    "                hog_features = feature.hog(proposal_img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "                # make a prediction using the SVM\n",
    "                pred = clf.predict(hog_features.reshape(1, -1))\n",
    "                if pred[0] > 0:\n",
    "                    non_overlapping = True\n",
    "                    for other_box in non_overlapping_boxes:\n",
    "                        iou = IoU(box, other_box)\n",
    "                        if iou > 0.25:\n",
    "                            non_overlapping = False\n",
    "                            break\n",
    "                    if non_overlapping:\n",
    "                        #print(pred)\n",
    "                        non_overlapping_boxes.append(box)\n",
    "            # write the non-overlapping boxes to the CSV file\n",
    "            for box in non_overlapping_boxes:\n",
    "                x, y, w, h = box\n",
    "                score = 0.0  # set score to 0 for now\n",
    "                writer.writerow([n, x, y, h, w, score])\n",
    "            # draw the non-overlapping boxes on the image\n",
    "            for box in non_overlapping_boxes:\n",
    "                x, y, w, h = box\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            # save the image with boxes drawn on it\n",
    "            save_path = os.path.join(save_dir, filename)\n",
    "            cv2.imwrite(save_path, image)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def get_box_from_labels(image_name, labels_file='data/labels.csv'):\n",
    "    \"\"\"Returns the list of bounding boxes for the given image_name in the labels_file.\"\"\"\n",
    "    #print(\"file\", image_name)\n",
    "    with open(labels_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        #next(reader)  # skip header row\n",
    "        boxes = []\n",
    "        for row in reader:\n",
    "            if row[0] == image_name:\n",
    "                y, x, h, w, s = map(int, row[1:])\n",
    "                boxes.append((x, y, w, h))\n",
    "        return boxes\n",
    "\n",
    "    \n",
    "def test_model_sw(clf, test_images_dir='data/test', save_dir='data/results', result_file='data/result.csv', debug=False):\n",
    "    with open(result_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['n', 'i', 'j', 'h', 'l', 's'])  # header row\n",
    "        filenames = os.listdir(test_images_dir)\n",
    "        random.shuffle(filenames)\n",
    "\n",
    "        for n, filename in enumerate(filenames):\n",
    "            if not filename.endswith('.jpg'):\n",
    "                continue\n",
    "            print(filename)\n",
    "            image_path = os.path.join(test_images_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            plt.imshow(image)\n",
    "            img_height, img_width = image.shape[:2]\n",
    "            true_height, true_width = image.shape[:2]\n",
    "            \n",
    "            window_factor = 15\n",
    "            window_size = (int(min(img_width,img_height)/window_factor),int(2 * min(img_width,img_height)/window_factor))\n",
    "            window_size = (100, 200)\n",
    "            boxes_found = []\n",
    "            sizes = [70, 100]\n",
    "            ratios = [1.5, 1.75, 2]\n",
    "\n",
    "            for size in sizes:\n",
    "                for ratio in ratios:\n",
    "                    window_size = (int(size), int(size * ratio))\n",
    "                    image = cv2.imread(image_path)\n",
    "                    for n in range(8):\n",
    "                        img_height, img_width = image.shape[:2]\n",
    "                        w, h = window_size\n",
    "                        for i in range(0, img_height - window_size[1], int(window_size[1]/3)):\n",
    "                            for j in range(0, img_width - window_size[0], int(window_size[0]/3)):\n",
    "                                x, y = j, i\n",
    "                                proposal_img = image[y:y+h,x:x+w]\n",
    "                                if proposal_img.shape != (h, w, 3):\n",
    "                                    break\n",
    "                                # resize the image to (100, 200)\n",
    "                                proposal_img = cv2.resize(proposal_img, (100, 200))\n",
    "                                # encode the image as HOG features\n",
    "                                hog_features = feature.hog(proposal_img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "                                # make a prediction using the SVM\n",
    "                                proba = clf.predict_proba(hog_features.reshape(1, -1))\n",
    "                                if proba[0][1] > 0.55:\n",
    "                                    scale_x = true_width / img_width\n",
    "                                    scale_y = true_height / img_height\n",
    "                                    true_x = int(x * scale_x)\n",
    "                                    true_y = int(y * scale_y)\n",
    "                                    true_w = int(w * scale_x)\n",
    "                                    true_h = int(h * scale_y)\n",
    "                                    box = (true_x, true_y, true_w, true_h)\n",
    "                                    boxes_found.append([box, proba[0][1]])\n",
    "\n",
    "                        image = cv2.resize(image, (int(img_width*0.85), int(img_height*0.8)))\n",
    "            image = cv2.imread(image_path)\n",
    "            # sort boxes by probability\n",
    "            boxes_found = sorted(boxes_found, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            # loop through boxes and remove those with high IoU\n",
    "            boxes_to_remove = []\n",
    "            for i in range(len(boxes_found)):\n",
    "                for j in range(i+1, len(boxes_found)):\n",
    "                    iou = IoU(boxes_found[i][0], boxes_found[j][0])\n",
    "                    if iou > 0.5:\n",
    "                        boxes_to_remove.append(j)\n",
    "            boxes_to_remove = list(set(boxes_to_remove))\n",
    "            boxes_found = [box for i, box in enumerate(boxes_found) if i not in boxes_to_remove]\n",
    "\n",
    "            # loop through remaining boxes and test against labels\n",
    "            if debug:\n",
    "                name, ext = os.path.splitext(filename)\n",
    "                labels = get_box_from_labels(name)\n",
    "                for box in boxes_found:\n",
    "                    has_label = False\n",
    "                    for label in labels:\n",
    "                        iou = IoU(box[0], label)\n",
    "                        if iou >= 0.3:\n",
    "                            has_label = True\n",
    "                            break\n",
    "                    if not has_label:\n",
    "                        # Add image to negative training dataset\n",
    "                        negative_img = image[box[0][1]:box[0][1]+box[0][3], box[0][0]:box[0][0]+box[0][2]]\n",
    "                        negative_img = cv2.resize(negative_img, (100, 200))\n",
    "                        cv2.imwrite(os.path.join('data/negative_images', f\"false_positive_{str(uuid.uuid4())[:8]}.jpg\"), negative_img)\n",
    "\n",
    "            # write the non-overlapping boxes to the CSV file\n",
    "            for box in boxes_found:\n",
    "                x, y, w, h = box[0]\n",
    "                score = box[1]\n",
    "                writer.writerow([n, x, y, h, w, score])\n",
    "            # draw the non-overlapping boxes on the image\n",
    "            for box in boxes_found:\n",
    "                x, y, w, h = box[0]\n",
    "                score = box[1]\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, int((score-0.55) * 255*45), 0), 2)\n",
    "            # save the image with boxes drawn on it\n",
    "            save_path = os.path.join(save_dir, filename)\n",
    "            cv2.imwrite(save_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aleymari_pos_008.jpg\n",
      "linsongt_pos_008.jpg\n",
      "aloechne_pos_005.jpg\n",
      "vduroche_pos_001.jpg\n",
      "pmarvier_pos_008.jpg\n",
      "nvengeon_pos_008.jpg\n",
      "tmoricea_pos_005.jpg\n"
     ]
    }
   ],
   "source": [
    "test_model_sw(clf, test_images_dir='data/images/pos/', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_pos_images()\n",
    "#augment_pos_images(num_images=10)\n",
    "generate_negative_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pos img\n",
      "loading neg img\n",
      "train model\n",
      "Validation accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "clf = train_svm_with_hog()\n",
    "#clf = train_svm_poly()\n",
    "#clf = train_rf_with_hog()\n",
    "#clf = train_adaboost_with_hog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('data/svm_model2.joblib')\n",
    "#clf = joblib.load('data/svm_modelpoly.joblib')\n",
    "#clf = joblib.load('data/rf_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proposal_img = cv2.imread('data/')\n",
    "proposal_img = cv2.resize(proposal_img, (100, 200))\n",
    "plt.imshow(proposal_img)\n",
    "hog_features = hog(proposal_img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
    "\n",
    "pred = clf.decision_function(hog_features.reshape(1, -1))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "029.jpg\n",
      "051.jpg\n",
      "002.jpg\n",
      "144.jpg\n",
      "106.jpg\n",
      "027.jpg\n",
      "048.jpg\n",
      "021.jpg\n",
      "134.jpg\n",
      "127.jpg\n",
      "102.jpg\n",
      "104.jpg\n",
      "014.jpg\n",
      "090.jpg\n",
      "137.jpg\n",
      "078.jpg\n",
      "033.jpg\n",
      "129.jpg\n",
      "140.jpg\n",
      "109.jpg\n",
      "038.jpg\n",
      "130.jpg\n",
      "022.jpg\n",
      "017.jpg\n",
      "149.jpg\n",
      "056.jpg\n",
      "075.jpg\n",
      "120.jpg\n",
      "112.jpg\n",
      "097.jpg\n",
      "007.jpg\n",
      "069.jpg\n",
      "085.jpg\n",
      "108.jpg\n",
      "081.jpg\n",
      "054.jpg\n",
      "143.jpg\n",
      "094.jpg\n",
      "089.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_257115/1275001154.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model_sw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/test_old/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_257115/68869695.py\u001b[0m in \u001b[0;36mtest_model_sw\u001b[0;34m(clf, test_images_dir, save_dir, result_file, debug)\u001b[0m\n\u001b[1;32m    433\u001b[0m                         \u001b[0;31m#proposal_img = cv2.resize(proposal_img, (50, 100))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                         \u001b[0;31m# encode the image as HOG features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                         \u001b[0mhog_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcells_per_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                         \u001b[0;31m# make a prediction using the SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhog_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/feature/_hog.py\u001b[0m in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, multichannel)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morientation_histogram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mnormalized_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0m_hog_normalize_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/skimage/feature/_hog.py\u001b[0m in \u001b[0;36m_hog_normalize_block\u001b[0;34m(block, method, eps)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Selected block normalization method is invalid.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2297\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7ff13befe3a0> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'jpg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'jpeg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mretina_figure\u001b[0;34m(fig, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m\"\"\"format a figure as a pixel-doubled (retina) PNG\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mpngdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'retina'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;31m# Make sure that retina_figure acts just like print_figure and returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# None when the figure is empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m                 )\n\u001b[1;32m   2341\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_draw_disabled\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3141\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0m_draw_rasterized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists_rasterized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3064\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3065\u001b[0m             renderer, self, artists, self.figure.suppressComposite)\n\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             im, l, b, trans = self.make_image(\n\u001b[0m\u001b[1;32m    642\u001b[0m                 renderer, renderer.get_image_magnification())\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    947\u001b[0m         clip = ((self.get_clip_box() or self.axes.bbox) if self.get_clip_on()\n\u001b[1;32m    948\u001b[0m                 else self.figure.bbox)\n\u001b[0;32m--> 949\u001b[0;31m         return self._make_image(self._A, bbox, transformed_bbox, clip,\n\u001b[0m\u001b[1;32m    950\u001b[0m                                 magnification, unsampled=unsampled)\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rgb_to_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scalar_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 output_alpha = _resample(  # resample alpha channel\n\u001b[0m\u001b[1;32m    554\u001b[0m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[1;32m    555\u001b[0m                 output = _resample(  # resample rgb channels\n",
      "\u001b[0;32m~/anaconda3/envs/python38/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     _image.resample(data, out, transform,\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0m_interpd_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_model_sw(clf, test_images_dir='data/test_old/', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
